{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4e7a604",
   "metadata": {},
   "source": [
    "# Python Kullanarak WhatsApp Sohbet Duygu Analizi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef9c48b",
   "metadata": {},
   "source": [
    "Bu proje, WhatsApp sohbet geçmişini analiz ederek her bir mesajın duygusal tonunu belirlemeyi amaçlar. Proje, Python programlama dili ve NLTK (Natural Language Toolkit) kütüphanesi kullanılarak gerçekleştirilmiştir. İşte projenin adım adım özeti:\n",
    "\n",
    "1. Veri Okuma ve Hazırlama:\n",
    "\n",
    "- WhatsApp sohbet geçmişi, belirli bir dosya yolundan okunur ve satır satır işlenir.\n",
    "- Her bir mesajın tarih, saat, yazar ve içerik bilgileri ayrıştırılarak bir veri yapısına (liste) eklenir.\n",
    "2. Verilerin Pandas DataFrame'e Dönüştürülmesi:\n",
    "\n",
    "- Ayrıştırılan veriler, Pandas DataFrame'e dönüştürülerek daha kolay işlenebilir hale getirilir.\n",
    "- 'Date' sütunundaki tarihler, datetime formatına çevrilir.\n",
    "- Eksik veriler DataFrame'den çıkarılır.\n",
    "3. Duygu Analizi:\n",
    "\n",
    "- NLTK'nın VADER (Valence Aware Dictionary and sEntiment Reasoner) duygu analiz aracı kullanılarak her bir mesajın duygusal tonu analiz edilir.\n",
    "- Analiz sonuçları, her bir mesaj için pozitif, negatif ve nötr skorlar olarak DataFrame'e eklenir.\n",
    "4. Sonuçların Görselleştirilmesi ve Yazdırılması:\n",
    "\n",
    "- Analiz sonuçlarının özet bilgileri (DataFrame'in ilk beş satırı) ekrana yazdırılır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d1d0c80",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\users\\realb\\anaconda3\\lib\\site-packages (2.12.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7.0 in c:\\users\\realb\\anaconda3\\lib\\site-packages (from emoji) (4.9.0)\n",
      "Collecting wordcloud\n",
      "  Obtaining dependency information for wordcloud from https://files.pythonhosted.org/packages/f5/b0/247159f61c5d5d6647171bef84430b7efad4db504f0229674024f3a4f7f2/wordcloud-1.9.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading wordcloud-1.9.3-cp311-cp311-win_amd64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\realb\\anaconda3\\lib\\site-packages (from wordcloud) (1.24.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\realb\\anaconda3\\lib\\site-packages (from wordcloud) (10.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\realb\\anaconda3\\lib\\site-packages (from wordcloud) (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\realb\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\realb\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\realb\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\realb\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\realb\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (23.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\realb\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\realb\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\realb\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Downloading wordcloud-1.9.3-cp311-cp311-win_amd64.whl (300 kB)\n",
      "   ---------------------------------------- 0.0/300.2 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/300.2 kB ? eta -:--:--\n",
      "   -- ------------------------------------ 20.5/300.2 kB 320.0 kB/s eta 0:00:01\n",
      "   ----- --------------------------------- 41.0/300.2 kB 279.3 kB/s eta 0:00:01\n",
      "   ----------- --------------------------- 92.2/300.2 kB 521.8 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 153.6/300.2 kB 702.7 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 256.0/300.2 kB 983.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 300.2/300.2 kB 1.1 MB/s eta 0:00:00\n",
      "Installing collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.9.3\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji\n",
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d535fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import emoji\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "361c660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Düzenli İfade (Regex) Deseninin Tanımlanması\n",
    "def date_time(s):\n",
    "    pattern = '^([0-9]+)(\\/)([0-9]+)(\\/)([0-9]+), ([0-9]+):([0-9]+)[ ]?(AM|PM|am|pm)? -'\n",
    "    result = re.match(pattern, s)\n",
    "    if result:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977fb762",
   "metadata": {},
   "source": [
    "Bu satır, tarih ve saat formatını tanımlayan bir düzenli ifade (regex) deseni oluşturur. Bu desen şu bileşenlerden oluşur:\n",
    "\n",
    "- ^: Satırın başını ifade eder.\n",
    "- ([0-9]+): Bir veya daha fazla rakam (gün, ay veya yıl için).\n",
    "- (\\/): Eğik çizgi (\"/\") karakteri.\n",
    "- ([0-9]+): Bir veya daha fazla rakam (gün, ay veya yıl için).\n",
    "- (\\/): Eğik çizgi (\"/\") karakteri.\n",
    "- ([0-9]+): Bir veya daha fazla rakam (gün, ay veya yıl için).\n",
    "- , : Virgül ve boşluk karakteri.\n",
    "- ([0-9]+): Bir veya daha fazla rakam (saat için).\n",
    "- :([0-9]+): İki nokta üst üste ve bir veya daha fazla rakam (dakika için).\n",
    "- [ ]?: İsteğe bağlı bir boşluk karakteri.\n",
    "- (AM|PM|am|pm)?: İsteğe bağlı olarak büyük veya küçük harflerle \"AM\" veya \"PM\".\n",
    "- -: Bir boşluk ve ardından kısa çizgi karakteri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "817b3c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yazarları veya Kişileri Bul\n",
    "def find_author(s):\n",
    "    s = s.split(\":\")\n",
    "    if len(s)==2:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0ae0a5",
   "metadata": {},
   "source": [
    "find_author(s) fonksiyonu, verilen bir metin satırının bir yazar adı (author) içerip içermediğini kontrol etmek için kullanılır. Bu, özellikle WhatsApp sohbet günlüklerinde her mesajın başındaki yazar adını tanımak için yararlı olabilir. Eğer metin : karakterine göre iki parçaya ayrılabiliyorsa, fonksiyon bu metnin bir yazar adı içerdiğini varsayar ve True döner. Aksi takdirde False döner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cea53376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mesajları Bulma\n",
    "def getDatapoint(line):\n",
    "    splitline = line.split(' - ')\n",
    "    dateTime = splitline[0]\n",
    "    date, time = dateTime.split(\", \")\n",
    "    message = \" \".join(splitline[1:])\n",
    "    if find_author(message):\n",
    "        splitmessage = message.split(\": \")\n",
    "        author = splitmessage[0]\n",
    "        message = \" \".join(splitmessage[1:])\n",
    "    else:\n",
    "        author= None\n",
    "    return date, time, author, message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58d9169",
   "metadata": {},
   "source": [
    "getDatapoint(line) fonksiyonu, belirli bir formatta verilen bir metin satırını işleyerek tarih, saat, yazar adı (varsa) ve mesaj içeriğini ayırır. Fonksiyon, metni belirli parçalara böler ve gerekli bilgileri ayrıştırarak döndürür. Bu, özellikle sohbet verilerini analiz etmek için kullanışlı olabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d6da4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "conversation = r'C:\\Users\\realb\\Desktop\\Python_kullanılarak_mesajlasma_analiz_etme\\‎ilker ile WhatsApp Sohbeti.txt'\n",
    "with open(conversation, encoding=\"utf-8\") as fp:\n",
    "    fp.readline()\n",
    "    messageBuffer = []\n",
    "    date, time, author = None, None, None\n",
    "    while True:\n",
    "        line = fp.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        line = line.strip()\n",
    "        if date_time(line):\n",
    "            if len(messageBuffer) > 0:\n",
    "                data.append([date, time, author, ' '.join(messageBuffer)])\n",
    "            messageBuffer.clear()\n",
    "            date, time, author, message = getDatapoint(line)\n",
    "            messageBuffer.append(message)\n",
    "        else:\n",
    "            messageBuffer.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64086d9a",
   "metadata": {},
   "source": [
    "Bu kod, WhatsApp sohbet dosyasını satır satır okuyarak her bir mesajın tarih, saat, yazar ve içerik bilgilerini ayrıştırır ve bunları bir listeye ekler. Sonuç olarak, her bir mesajın detaylı bilgilerini içeren bir data listesi elde edilir. Bu, özellikle sohbet verilerini analiz etmek veya işlemek için kullanışlıdır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa209261",
   "metadata": {},
   "source": [
    "Sematik analaiz yapacak olan kütüpanenin indiriyorum ve bunun kontrölünü yapıyorum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbec2de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\realb\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3b7572a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Date, Time, Author, Message, Positive, Negative, Neutral]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data, columns=[\"Date\", 'Time', 'Author', 'Message'])\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "data = df.dropna()\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sentiments = SentimentIntensityAnalyzer()\n",
    "data[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in data[\"Message\"]]\n",
    "data[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in data[\"Message\"]]\n",
    "data[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in data[\"Message\"]]\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4061cf97",
   "metadata": {},
   "source": [
    "Bu kod, WhatsApp sohbet verilerini işleyerek her bir mesajın duygusal tonunu analiz eder. Bu analiz, mesajların pozitif, negatif ve nötr skorlarını içerir ve sonuçları bir Pandas DataFrame'e kaydeder. Bu, sohbet verilerinin duygusal dağılımını anlamak için kullanılabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d64bd16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral 🙂 \n"
     ]
    }
   ],
   "source": [
    "x = sum(data[\"Positive\"])\n",
    "y = sum(data[\"Negative\"])\n",
    "z = sum(data[\"Neutral\"])\n",
    "\n",
    "def sentiment_score(a, b, c):\n",
    "    if (a>b) and (a>c):\n",
    "        print(\"Positive 😊 \")\n",
    "    elif (b>a) and (b>c):\n",
    "        print(\"Negative 😠 \")\n",
    "    else:\n",
    "        print(\"Neutral 🙂 \")\n",
    "sentiment_score(x, y, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb58d92",
   "metadata": {},
   "source": [
    "Dönüşümü yapılan datafrema üzerinden işlem yapılarak duygu analizi yapılmasını sağlıyor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
